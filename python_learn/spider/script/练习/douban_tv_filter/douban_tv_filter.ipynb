{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取指定类型电视剧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://m.douban.com/rexxar/api/v2/tv/recommend?refresh=0&start=0&count=20&selected_categories={\"地区\":\"华语\"}&uncollect=false&tags=华语\n",
      "https://m.douban.com/rexxar/api/v2/tv/recommend?refresh=0&start=20&count=20&selected_categories={\"地区\":\"华语\"}&uncollect=false&tags=华语\n"
     ]
    }
   ],
   "source": [
    "#抓取数据进行解析\n",
    "# https://m.douban.com/rexxar/api/v2/tv/recommend?refresh=0&start=0&count=20&selected_categories=%7B%22%E5%9C%B0%E5%8C%BA%22:%22%E5%8D%8E%E8%AF%AD%22%7D&uncollect=false&tags=%E5%8D%8E%E8%AF%AD\n",
    "# https://m.douban.com/rexxar/api/v2/tv/recommend?refresh=0&start=20&count=20&selected_categories=%7B%22%E5%9C%B0%E5%8C%BA%22:%22%E5%8D%8E%E8%AF%AD%22%7D&uncollect=false&tags=%E5%8D%8E%E8%AF%AD\n",
    "import urllib\n",
    "\n",
    "url_init1 = ('https://m.douban.com/rexxar/api/v2/tv/recommend?refresh=0&start=0&count=20&selected_categories=%7B%22%E5%9C%B0%E5%8C%BA%22:%22%E5%8D%8E%E8%AF%AD%22%7D&uncollect=false&tags=%E5%8D%8E%E8%AF%AD')\n",
    "url_init2=('https://m.douban.com/rexxar/api/v2/tv/recommend?refresh=0&start=20&count=20&selected_categories=%7B%22%E5%9C%B0%E5%8C%BA%22:%22%E5%8D%8E%E8%AF%AD%22%7D&uncollect=false&tags=%E5%8D%8E%E8%AF%AD')\n",
    "url1 = urllib.parse.unquote(url_init1)\n",
    "url2=urllib.parse.unquote(url_init2)\n",
    "print(url1)\n",
    "print(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'refresh': ['0'],\n",
       " 'start': ['20'],\n",
       " 'count': ['20'],\n",
       " 'selected_categories': ['{\"地区\":\"华语\"}'],\n",
       " 'uncollect': ['false'],\n",
       " 'tags': ['华语']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取对应的参数\n",
    "query = urllib.parse.urlparse(url2).query\n",
    "params = urllib.parse.parse_qs(query)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_one_request(url, headers, params):\n",
    "    res = None\n",
    "    cnt = 0\n",
    "    while cnt <= 3:\n",
    "        req = requests.get(url, headers=headers, params=params)\n",
    "        if req.status_code == 200:\n",
    "            res = json.loads(req.text)\n",
    "            #res保存为json文件\n",
    "            with open('douban.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(res, f, ensure_ascii=False, indent=4)\n",
    "            break\n",
    "        else:\n",
    "            cnt += 1\n",
    "            continue\n",
    "          \n",
    "    return res\n",
    "\n",
    "def get_origin_data(page_cnt):\n",
    "    res_list = []\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "        'Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.41',\n",
    "        'Referer': 'https://movie.douban.com/explore'\n",
    "    }\n",
    "    url_base = 'https://m.douban.com/rexxar/api/v2/tv/recommend?'\n",
    "    params = {\n",
    "        'refresh': ['0'],\n",
    "        'start': ['0'],\n",
    "        'count': ['20'],\n",
    "        'selected_categories': ['{\"地区\":\"华语\"}'],\n",
    "        'uncollect': ['false'],\n",
    "        'tags': ['华语']\n",
    "    }\n",
    "    for i in range(page_cnt):\n",
    "        start = str(i * 20)\n",
    "        params['start'] = [start]\n",
    "        res = get_one_request(url_base, headers, params)\n",
    "        res_list.append(res)\n",
    "        time.sleep(1)\n",
    "      \n",
    "    return res_list\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    page_cnt = 1\n",
    "    data = get_origin_data(page_cnt)\n",
    "    data_clean = [j for i in range(len(data)) \n",
    "                  for j in data[i]['items']]\n",
    "    df = pd.DataFrame(data_clean)\n",
    "    df[['title', 'year', 'card_subtitle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df是json格式的数据，需要将其转换为csv格式\n",
    "df.to_csv('douban.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df保存为json格式\n",
    "df.to_json('douban.json', orient='records', force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('douban.json','r',encoding='utf-8')\n",
    "data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "花儿与少年·丝路季 2023 2023 / 中国大陆 / 真人秀 / 李超 / 秦海璐 秦岚 4.5\n",
      "繁花 2023 2023 / 中国大陆 / 剧情 爱情 / 王家卫 / 胡歌 马伊琍 4.5\n",
      "要久久爱 2024 2024 / 中国大陆 / 剧情 / 牛超 马成成 / 杨紫 范丞丞 0.0\n",
      "仙剑四 2024 2024 / 中国大陆 / 剧情 奇幻 古装 / 杨玄 黄埜 / 鞠婧祎 陈哲远 2.0\n",
      "大江大河之岁月如歌 2024 2024 / 中国大陆 / 剧情 / 孔笙 孙墨龙 刘洪源 / 王凯 杨烁 4.0\n",
      "祈今朝 2024 2024 / 中国大陆 / 剧情 爱情 奇幻 古装 / 刘国楠 / 许凯 虞书欣 2.5\n",
      "你也有今天 2024 2024 / 中国大陆 / 剧情 爱情 / 陈铭章 陈世峄 / 陈星旭 章若楠 3.5\n",
      "如果奔跑是我的人生 2024 2024 / 中国大陆 / 剧情 / 沈严 李江明 / 钟楚曦 杨超越 3.5\n",
      "漫长的季节 2023 2023 / 中国大陆 / 剧情 家庭 犯罪 / 辛爽 / 范伟 秦昊 4.5\n",
      "莲花楼 2023 2023 / 中国大陆 / 剧情 悬疑 武侠 古装 / 郭虎 任海涛 / 成毅 曾舜晞 4.5\n",
      "在暴雪时分 2024 2024 / 中国大陆 / 剧情 爱情 / 黄天仁 / 吴磊 赵今麦 0.0\n",
      "黑土无言 2024 2024 / 中国大陆 / 剧情 悬疑 犯罪 / 臧溪川 / 陈建斌 胡军 3.5\n",
      "三大队 2023 2023 / 中国大陆 / 动作 悬疑 犯罪 / 邢键钧 / 秦昊 李乃文 3.5\n",
      "狂飙 2023 2023 / 中国大陆 / 剧情 犯罪 / 徐纪周 / 张译 张颂文 4.5\n",
      "长相思 2023 2023 / 中国大陆 / 爱情 奇幻 古装 / 秦榛 杨欢 / 杨紫 张晚意 4.0\n",
      "狗剩快跑 2024 2024 / 中国大陆 / 喜剧 历史 战争 / 王新军 / 蒋龙 史策 0.0\n",
      "后宫·甄嬛传 2011 2011 / 中国大陆 / 剧情 古装 / 郑晓龙 / 孙俪 陈建斌 4.5\n",
      "神隐 2023 2023 / 中国大陆 / 剧情 爱情 奇幻 古装 / 陈家霖 李才 / 赵露思 王安宇 3.0\n",
      "长歌行 2021 2021 / 中国大陆 / 剧情 古装 / 朱锐斌 / 迪丽热巴 吴磊 3.0\n",
      "新闻女王 2023 2023 / 中国香港 中国大陆 / 剧情 / 陈海斌 姜振杰 / 佘诗曼 马国明 4.0\n"
     ]
    }
   ],
   "source": [
    "for i in data['items']:\n",
    "    print(i['title'],i['year'],i['card_subtitle'],i['rating']['star_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#访问网站获取数据\n",
    "import csv\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "def Get_request(url,headers,params):\n",
    "    print('tt')\n",
    "    try:\n",
    "        print('hh')\n",
    "        r=requests.get(url,headers=headers,params=params,timeout=30)\n",
    "        r.raise_for_status()\n",
    "        print(r.status_code)        \n",
    "        res = json.loads(r.text)\n",
    "        return res\n",
    "    except:\n",
    "        print('error')\n",
    "        return 'ERROR!!'\n",
    "\n",
    "def Save_file(res):\n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "\n",
    "    with open('DoubanTv.csv', 'a', newline='', encoding='utf-8') as dbtv:\n",
    "        writer = csv.writer(dbtv)\n",
    "        for item in res['items']:\n",
    "            Info = (\n",
    "                item['id'],\n",
    "                item['title'],\n",
    "                item['rating']['value'],\n",
    "                item['card_subtitle'],\n",
    "                item['year'],\n",
    "                item['pic']['large']\n",
    "            )\n",
    "            writer.writerow(Info)\n",
    "\n",
    "            # Download and save the image\n",
    "            image_url = item['pic']['large']\n",
    "            response = requests.get(image_url)\n",
    "            if response.status_code == 200:\n",
    "                with open(f'images/{item[\"id\"]}.jpg', 'wb') as img:\n",
    "                    img.write(response.content)\n",
    "        \n",
    "\n",
    "def Get_data(page_cnt):\n",
    "    base_url='https://m.douban.com/rexxar/api/v2/tv/recommend?'\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',\n",
    "               'Referer': 'https://movie.douban.com/explore'}\n",
    "    params = {\n",
    "        'refresh': ['0'],\n",
    "        'start': ['0'],\n",
    "        'count': ['20'],\n",
    "        'selected_categories': ['{\"地区\":\"华语\"}'],\n",
    "        'uncollect': ['false'],\n",
    "        'tags': ['华语']\n",
    "    }\n",
    "    try:\n",
    "        for i in range(page_cnt):\n",
    "            start = str(i * 20)\n",
    "            params['start'] = [start]\n",
    "            print(base_url,params)\n",
    "            res=Get_request(base_url,headers,params)\n",
    "            Save_file(res)\n",
    "            time.sleep(5)\n",
    "    except:\n",
    "        return 'Get error maybe have done!!'\n",
    "\n",
    "          \n",
    "def main():\n",
    "    page_cnt=100\n",
    "    Get_data(page_cnt)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入DoubanTv.csv\n",
    "import pandas as pd\n",
    "\n",
    "tv_data=pd.read_csv(r'D:\\000zyf\\Learning\\python_learn\\spider\\script\\练习\\douban_tv_filter\\DoubanTv.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pachong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
